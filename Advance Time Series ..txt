#===============================================
# Advance Multivariate Time Series Forecasting
# Transformer vs LSTM vs SARIMAX
#===============================================

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.statespace.sarimax import SARIMAX
import warnings
warnings.filterwarnings("ignore")

np.random.seed(42)
tf.random.set_seed(42)

# --------------------
# Data generation
# --------------------
def generate_data(n_steps=1500):
    t = np.arange(n_steps)
    energy = 0.05*t + 10*np.sin(2*np.pi*t/24) + np.random.normal(0,1,n_steps)
    temp = 20 + 5*np.sin(2*np.pi*t/365) + np.random.normal(0,0.5,n_steps)
    humidity = 60 + 10*np.sin(2*np.pi*t/168) + np.random.normal(0,2,n_steps)
    return pd.DataFrame({
        "energy": energy,
        "temperature": temp,
        "humidity": humidity
    })

data = generate_data()

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

# --------------------
# Sequence generator
# --------------------
def create_sequences(data, window, horizon):
    X, y = [], []
    for i in range(len(data) - window - horizon):
        X.append(data[i:i+window])
        y.append(data[i+window:i+window+horizon, 0])
    return np.array(X), np.array(y)

# --------------------
# Metrics
# --------------------
def metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred)/y_true)) * 100
    return rmse, mae, mape

# --------------------
# Positional Encoding
# --------------------
class PositionalEncoding(layers.Layer):
    def _init_(self, seq_len, embed_dim):
        super()._init_()
        pos = np.arange(seq_len)[:, None]
        i = np.arange(embed_dim)[None, :]
        angle_rates = 1 / np.power(10000, (2*(i//2))/embed_dim)
        angle_rads = pos * angle_rates
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        self.pos_encoding = tf.cast(angle_rads[None, ...], tf.float32)

    def call(self, x):
        return x + self.pos_encoding[:, :tf.shape(x)[1], :]

# --------------------
# Transformer Block
# --------------------
class TransformerBlock(layers.Layer):
    def _init_(self, embed_dim, num_heads, ff_dim):
        super()._init_()
        self.att = layers.MultiHeadAttention(num_heads, embed_dim)
        self.ffn = models.Sequential([
            layers.Dense(ff_dim, activation="relu"),
            layers.Dense(embed_dim)
        ])
        self.norm1 = layers.LayerNormalization()
        self.norm2 = layers.LayerNormalization()

    def call(self, x):
        attn = self.att(x, x)
        x = self.norm1(x + attn)
        ffn = self.ffn(x)
        return self.norm2(x + ffn)

# --------------------
# Model builders
# --------------------
def build_lstm(window, features, horizon):
    model = models.Sequential([
        layers.LSTM(64, return_sequences=True, input_shape=(window, features)),
        layers.LSTM(32),
        layers.Dense(horizon)
    ])
    model.compile(optimizer="adam", loss="mse")
    return model

def build_transformer(window, features, horizon):
    inputs = layers.Input(shape=(window, features))
    x = layers.Dense(64)(inputs)
    x = PositionalEncoding(window, 64)(x)
    for _ in range(3):
        x = TransformerBlock(64, 4, 128)(x)
    x = layers.GlobalAveragePooling1D()(x)
    outputs = layers.Dense(horizon)(x)
    model = models.Model(inputs, outputs)
    model.compile(optimizer="adam", loss="mse")
    return model

# --------------------
# Training & Evaluation
# --------------------
WINDOW = 48
HORIZONS = [1, 5, 10]
results = []

for H in HORIZONS:
    X, y = create_sequences(scaled_data, WINDOW, H)
    split = int(0.8 * len(X))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    lstm = build_lstm(WINDOW, 3, H)
    lstm.fit(X_train, y_train, epochs=15, batch_size=32, verbose=0)
    lstm_pred = lstm.predict(X_test)
    results.append(["LSTM", H, *metrics(y_test.flatten(), lstm_pred.flatten())])

    transformer = build_transformer(WINDOW, 3, H)
    transformer.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)
    trans_pred = transformer.predict(X_test)
    results.append(["Transformer", H, *metrics(y_test.flatten(), trans_pred.flatten())])

    sarimax = SARIMAX(
        data["energy"][:split],
        order=(2,1,2),
        seasonal_order=(1,1,1,24)
    ).fit(disp=False)
    sar_pred = sarimax.forecast(len(y_test))
    results.append(["SARIMAX", H, *metrics(y_test[:,0], sar_pred)])

# --------------------
# Final Results
# --------------------
result_df = pd.DataFrame(
    results,
    columns=["Model", "Horizon", "RMSE", "MAE", "MAPE (%)"]
)

print("\n=== Final Model Comparison ===")
print(result_df)